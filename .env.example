# CapyCut Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# ===========================================
# Option 1: Local LLM (FREE - recommended!)
# ===========================================
# Works with LM Studio, Ollama, or any OpenAI-compatible server
# No API key needed!

# LM Studio (default port 1234):
# LLM_ENDPOINT=http://localhost:1234

# Ollama (default port 11434):
# LLM_ENDPOINT=http://localhost:11434
# LLM_MODEL=llama3.2

# ===========================================
# Option 2: Azure OpenAI
# ===========================================
# Get these from your Azure OpenAI resource in the Azure Portal

# AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com
# AZURE_OPENAI_API_KEY=your-api-key-here
# AZURE_OPENAI_MODEL=gpt-4o
# AZURE_OPENAI_API_VERSION=2025-04-01-preview
